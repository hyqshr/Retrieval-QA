{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 智能问答系统（主文件）\n",
    "\n",
    "在这里我们来搭建一个轻量级智能问答系统，所需要的模块，包括：\n",
    "- 文本预处理：这部分已经帮大家写好，只需要看看代码就可以了。\n",
    "- 搭建意图识别分类器：这部分也给大家写好了，使用fastText来做的意图识别器\n",
    "- 倒排表：这部分大家需要自己去创建，同时也需要考虑相似的单词（课程视频中讲过）\n",
    "- 排序：基于倒排表返回的结果，我们再根据余弦相似度来计算query跟候选问题之间的相似度，最后返回相似度最高的问题的答案。这里，我们将使用BERT来表示句子的向量。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %env KMP_DUPLICATE_LIB_OK=TRUE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import emoji\n",
    "import re\n",
    "import jieba\n",
    "import torch\n",
    "import fasttext\n",
    "from sys import platform\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取已经处理好的数据： 导入在preprocessor.ipynb中生成的data/question_answer_pares.pkl文件，并将其保存在变量QApares中\n",
    "with open('data/question_answer_pares.pkl','rb') as f:\n",
    "    QApares = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入在Retrieve.ipynb中生成的data/retrieve/invertedList.pkl倒排表文件，并将其保存在变量invertedList中\n",
    "with open('data/retrieve/invertedList.pkl','rb') as f:\n",
    "    invertedList = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这一格的内容是从preprocessor.ipynb中粘贴而来，包含了数据预处理的几个关键函数，这部分用来处理input query string\n",
    "import emoji\n",
    "import re\n",
    "import jieba\n",
    "def clean(content):\n",
    "    content = emoji.demojize(content)\n",
    "    content = re.sub('<.*>','',content)\n",
    "    return content\n",
    "def question_cut(content):\n",
    "    return list(jieba.cut(content))\n",
    "def strip(wordList):\n",
    "    return [word.strip() for word in wordList if word.strip()!='']\n",
    "with open(\"data/stopWord.json\",\"r\") as f:\n",
    "    stopWords = f.read().split(\"\\n\")\n",
    "def rm_stop_word(wordList):\n",
    "    return [word for word in wordList if word not in stopWords]\n",
    "\n",
    "def text_processing(sentence):\n",
    "    sentence = clean(sentence)\n",
    "    sentence = question_cut(sentence)\n",
    "    sentence = strip(sentence)\n",
    "    sentence = rm_stop_word(sentence)\n",
    "    return sentence\n",
    "\n",
    "# 这一格是从Retrieve中粘贴而来，用于生成与输入数据较相近的一些候选问题的index\n",
    "def get_retrieve_result(sentence):\n",
    "    \"\"\"\n",
    "    基于输入句子，并利用倒排表返回candidate sentence ids\n",
    "    \"\"\"\n",
    "    sentence = text_processing(sentence)\n",
    "    candidate = set()\n",
    "    for word in sentence:\n",
    "        if word in invertedList:\n",
    "            candidate = candidate | invertedList[word]\n",
    "    return sentence, candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# 加载训练好的fasttext模型用于意图识别\n",
    "intention = fasttext.load_model('model/fasttext.ftz')\n",
    "\n",
    "def get_intention_result(sentence):\n",
    "    '''\n",
    "        输入句子，返回意图识别结果\n",
    "        入参：\n",
    "            sentence:输入的句子\n",
    "        出参:\n",
    "            fasttext_label:fasttext模型的输出，共有两种结果:__label__0和__label__1。__label__0表示闲聊型，__label__1表示任务型\n",
    "    '''\n",
    "    sentence = text_processing(sentence)\n",
    "    sentence = ' '.join(sentence)\n",
    "    fasttext_label = intention.predict(sentence)[0][0]\n",
    "    return fasttext_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_after_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>买二份有没有少点呀</td>\n",
       "      <td>亲亲真的不好意思我们已经是优惠价了呢小本生意请亲谅解</td>\n",
       "      <td>[买, 二份, 有没有, 少点]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>那就等你们处理喽</td>\n",
       "      <td>好的亲退了</td>\n",
       "      <td>[处理]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>那我不喜欢</td>\n",
       "      <td>颜色的话一般茶刀茶针和二合一的话都是红木檀和黑木檀哦</td>\n",
       "      <td>[喜欢]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>不是免运费</td>\n",
       "      <td>本店茶具订单满99包邮除宁夏青海内蒙古海南新疆西藏满39包邮</td>\n",
       "      <td>[免, 运费]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>好吃吗</td>\n",
       "      <td>好吃的</td>\n",
       "      <td>[好吃]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question                          answer question_after_preprocessing\n",
       "0  买二份有没有少点呀      亲亲真的不好意思我们已经是优惠价了呢小本生意请亲谅解             [买, 二份, 有没有, 少点]\n",
       "1   那就等你们处理喽                           好的亲退了                         [处理]\n",
       "2      那我不喜欢      颜色的话一般茶刀茶针和二合一的话都是红木檀和黑木檀哦                         [喜欢]\n",
       "3      不是免运费  本店茶具订单满99包邮除宁夏青海内蒙古海南新疆西藏满39包邮                      [免, 运费]\n",
       "4        好吃吗                             好吃的                         [好吃]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QApares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_vec(l):\n",
    "    c = 0\n",
    "    total = np.zeros(300)\n",
    "    for word in l:\n",
    "        if word in model.vocab:\n",
    "            total += model[word]\n",
    "            c += 1\n",
    "    if c > 0:\n",
    "        return total/c\n",
    "    else:\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用word2vec来得到每一个回复的doc vector (同第一次项目)\n",
    "# 也可以使用bert\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('data/retrieve/sgns.zhihu.word')\n",
    "QApares['docvec'] = QApares['question_after_preprocessing'].apply(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_after_preprocessing</th>\n",
       "      <th>docvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>买二份有没有少点呀</td>\n",
       "      <td>亲亲真的不好意思我们已经是优惠价了呢小本生意请亲谅解</td>\n",
       "      <td>[买, 二份, 有没有, 少点]</td>\n",
       "      <td>[-0.13097949884831905, 0.28594200732186437, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>那就等你们处理喽</td>\n",
       "      <td>好的亲退了</td>\n",
       "      <td>[处理]</td>\n",
       "      <td>[0.05896899849176407, 0.4832009971141815, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>那我不喜欢</td>\n",
       "      <td>颜色的话一般茶刀茶针和二合一的话都是红木檀和黑木檀哦</td>\n",
       "      <td>[喜欢]</td>\n",
       "      <td>[-0.35680198669433594, 0.4411720037460327, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>不是免运费</td>\n",
       "      <td>本店茶具订单满99包邮除宁夏青海内蒙古海南新疆西藏满39包邮</td>\n",
       "      <td>[免, 运费]</td>\n",
       "      <td>[-0.2459930032491684, 0.27229949831962585, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>好吃吗</td>\n",
       "      <td>好吃的</td>\n",
       "      <td>[好吃]</td>\n",
       "      <td>[-0.44224798679351807, -0.11215300112962723, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question                          answer question_after_preprocessing  \\\n",
       "0  买二份有没有少点呀      亲亲真的不好意思我们已经是优惠价了呢小本生意请亲谅解             [买, 二份, 有没有, 少点]   \n",
       "1   那就等你们处理喽                           好的亲退了                         [处理]   \n",
       "2      那我不喜欢      颜色的话一般茶刀茶针和二合一的话都是红木檀和黑木檀哦                         [喜欢]   \n",
       "3      不是免运费  本店茶具订单满99包邮除宁夏青海内蒙古海南新疆西藏满39包邮                      [免, 运费]   \n",
       "4        好吃吗                             好吃的                         [好吃]   \n",
       "\n",
       "                                              docvec  \n",
       "0  [-0.13097949884831905, 0.28594200732186437, -0...  \n",
       "1  [0.05896899849176407, 0.4832009971141815, 0.04...  \n",
       "2  [-0.35680198669433594, 0.4411720037460327, -0....  \n",
       "3  [-0.2459930032491684, 0.27229949831962585, -0....  \n",
       "4  [-0.44224798679351807, -0.11215300112962723, -...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QApares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入与bert embedding相关的包，关于mxnet包下载的注意事项参考实验手册\n",
    "# from bert_embedding import BertEmbedding\n",
    "# import mxnet\n",
    "\n",
    "# ctx = mxnet.cpu()\n",
    "# embedding = BertEmbedding(ctx=ctx)\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    return np.dot(a,b.T) / ( (np.dot(a,a.T) **.5) * (np.dot(b,b.T) ** .5) )\n",
    "\n",
    "def get_best_answer(sentence, candidate):\n",
    "    \"\"\"\n",
    "    sentence: 用户输入query， 已经处理好的\n",
    "    candidate: 通过倒排表返回的候选问题的下标列表\n",
    "    \n",
    "    返回：最佳回复，string形式\n",
    "    \"\"\"\n",
    "    \n",
    "    ## TODO： 你需要完成这部分\n",
    "    ##   计算query跟每一个候选问题之间的余弦相似度，最后排序\n",
    "    ##   每个query跟候选问题首先要转化成向量形式，这里使用BERT embedding （可参考第一次项目作业）。 如果你想尝试，其他的embedding方法，也可以自行尝试如tf-idf\n",
    "    \n",
    "    ## 一下答案使用word2vec，bert原理一样\n",
    "    sentence_word2vec = doc_vec(sentence)\n",
    "    \n",
    "    maxIdx = -1\n",
    "    maxSimilarity = -1\n",
    "    \n",
    "    for c in candidate:\n",
    "        vec = QApares.iloc[c]['docvec']\n",
    "        similarity = cosine_similarity(sentence_word2vec, vec)\n",
    "        \n",
    "        if similarity > maxSimilarity:\n",
    "            maxSimilarity = similarity\n",
    "            maxIdx = c\n",
    "    \n",
    "    return QApares.iloc[c]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA(sentence):\n",
    "    '''\n",
    "        实现一个智能客服系统，输入一个句子sentence，返回一个回答\n",
    "    '''\n",
    "    # 若意图识别结果为闲聊型，则默认返回'闲聊机器人'\n",
    "    if get_intention_result(sentence)=='__label__0':\n",
    "        return '闲聊机器人'\n",
    "    # 根据倒排表进行检索获得候选问题集\n",
    "    sentence, candidate = get_retrieve_result(sentence)\n",
    "    # 若候选问题集大小为0，默认返回'我不明白你在说什么'\n",
    "    if len(candidate)==0:\n",
    "        return '我不明白你在说什么'\n",
    "    \n",
    "    return get_best_answer(sentence, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这个看当地快递派送的呢'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "QA('发什么快递')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'闲聊机器人'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "QA('怎么退款')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'榴莲干没货哦'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "QA('这个商品有优惠券吗')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我不明白你在说什么'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "QA('一二三四五六七')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
